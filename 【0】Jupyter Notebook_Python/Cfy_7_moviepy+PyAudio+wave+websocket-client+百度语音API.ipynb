{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【0】moviepy ：从mp4视频中抽取语音流数据并转换成wav格式音频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|                                | 0/5451 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in C:\\Users\\hp\\Desktop\\test.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "# 【0】moviepy ：从mp4视频中抽取语音流数据并转换成wav格式音频\n",
    "\n",
    "# 安装 pip install moviepy\n",
    "\n",
    "from moviepy.editor import *\n",
    "import os \n",
    "\n",
    "# desk_path=os.path.join(os.path.expanduser(\"~\"),\"Desktop\")\n",
    "# file_path=os.path.join(desk_path,'VBA+Acrobat.mp4')\n",
    "# fp,fn = os.path.split(file_path)\n",
    "# dir_name,suffix = os.path.splitext(fn)\n",
    "# print(os.path.splitext(fn))\n",
    "# cmd1 = f'mkdir {desk_path}\\\\{dir_name}'\n",
    "# os.system(cmd1)  # 新视频就建立个新目录存放\n",
    "\n",
    "# video = VideoFileClip(file_path)\n",
    "# audio = video.audio\n",
    "# audio.write_audiofile(f'{desk_path}\\\\{dir_name}\\\\{dir_name}.wav')  # 主要转化函数\n",
    "\n",
    "# ——————————————————————————————————————\n",
    "audio_file =r'C:\\Users\\hp\\Desktop\\test.wav'\n",
    "video = VideoFileClip(r\"C:\\Users\\hp\\Desktop\\Prac\\【3】VBA+API——Excel版沙雕音乐播放器.mp4\")\n",
    "video.audio.write_audiofile(audio_file,ffmpeg_params=['-ar','16000','-ac','1']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【1】ffmpeg ：音频文件转码——将wav转为pcm格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 【1】ffmpeg ：音频文件转码——将wav转为pcm格式\n",
    "\n",
    "import os\n",
    "\n",
    "# desk_path=os.path.join(os.path.expanduser(\"~\"),\"Desktop\",\"VBA+Acrobat\")\n",
    "# file_name = 'VBA+Acrobat.wav'\n",
    "# file_path=os.path.join(desk_path,file_name)\n",
    "# pcmfile_name=os.path.join(desk_path, 'VBA+Acrobat.pcm')\n",
    "\n",
    "# os.system(f\"ffmpeg -y -i {file_path} -acodec pcm_s16le -f s16le -ac 1 -ar 16000 {pcmfile_name}\")\n",
    "\n",
    "# ————————————————————————————————————————————————\n",
    "file_path=r\"C:\\Users\\hp\\Desktop\\test.wav\"\n",
    "pcmfile_name=r\"C:\\Users\\hp\\Desktop\\test.pcm\"\n",
    "\n",
    "os.system(f\"ffmpeg -y -i {file_path} -acodec pcm_s16le -f s16le -ac 1 -ar 16000 {pcmfile_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【2】百度 短语音识 别接口<=60s：REST-API-PythonSDK   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-10-04 20:27:22,434] [_new_conn()][DEBUG] Starting new HTTPS connection (1): aip.baidubce.com:443\n",
      "[2021-10-04 20:27:26,692] [_make_request()][DEBUG] https://aip.baidubce.com:443 \"GET /oauth/2.0/token?grant_type=client_credentials&client_id=YO7P7EaATIEzaFhRo6NlpghM&client_secret=5ySxlXiddOpXQUMgq9z3I9aaPREmOScG HTTP/1.1\" 200 None\n",
      "[2021-10-04 20:27:26,805] [_new_conn()][DEBUG] Starting new HTTP connection (1): 127.0.0.1:10809\n",
      "[2021-10-04 20:27:30,218] [_make_request()][DEBUG] http://127.0.0.1:10809 \"POST http://vop.baidu.com/server_api HTTP/1.1\" 200 141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "success.\n",
      "好好学习，天天向上。\n"
     ]
    }
   ],
   "source": [
    "# 【2】百度 短语音识 别接口<=60s：REST-API-PythonSDK   \n",
    "\n",
    "# 【技术文档】——https://ai.baidu.com/ai-doc/SPEECH/1k4o0bmc7\n",
    "# 目前本SDK的功能同REST API，需要联网调用http接口, 具体功能见REST API 文档, REST API 仅支持整段语音识别的模式，\n",
    "# 即需要上传完整语音文件进行识别，时长不超过60s，支持、自定义词库设置， 没有其他额外功能。\n",
    "\n",
    "# 【支持的语音格式】\n",
    "# 原始 PCM 的录音参数必须符合 16k、8k 采样率、16bit 位深、单声道，\n",
    "# 支持的格式有：pcm（不压缩）、wav（不压缩，pcm编码）、amr（压缩格式）。\n",
    "\n",
    "# 参数\t类型\t描述\t是否必须\n",
    "# speech\tBuffer\t建立包含语音内容的Buffer对象, 语音文件的格式，pcm 或者 wav 或者 amr。不区分大小写\t是\n",
    "# format\tString\t语音文件的格式，pcm 或者 wav 或者 amr。不区分大小写。推荐pcm文件\t是\n",
    "# rate\tint\t采样率，16000、8000，固定值\t是\n",
    "# cuid\tString\t用户唯一标识，用来区分用户，填写机器 MAC 地址或 IMEI 码，长度为60以内\t否\n",
    "# dev_pid\tInt\t不填写lan参数生效，都不填写，默认1537（普通话 输入法模型），dev_pid参数见本节开头的表格\t否\n",
    "# dev_pid 语种选择,输入法模型，默认中文（zh）。 中文=zh、粤语=ct、英文=en，不区分大小写。\t否\n",
    "#     dev_pid 参数列表\n",
    "#     dev_pid\t语言\t模型\t是否有标点\t备注\n",
    "#     1537\t普通话(纯中文识别)\t语音近场识别模型\t有标点\t支持自定义词库\n",
    "#     1737\t英语\t\t无标点\t不支持自定义词库\n",
    "#     1637\t粤语\t\t有标点\t不支持自定义词库\n",
    "#     1837\t四川话\t\t有标点\t不支持自定义词库\n",
    "#     1936\t普通话远场\t远场模型\t有标点\t不支持\n",
    "\n",
    "# 返回样例：\n",
    "\n",
    "# // 成功返回\n",
    "# {\n",
    "#     \"err_no\": 0,\n",
    "#     \"err_msg\": \"success.\",\n",
    "#     \"corpus_no\": \"15984125203285346378\",\n",
    "#     \"sn\": \"481D633F-73BA-726F-49EF-8659ACCC2F3D\",\n",
    "#     \"result\": [\"北京天气\"]\n",
    "# }\n",
    "\n",
    "# // 失败返回\n",
    "# {\n",
    "#     \"err_no\": 2000,\n",
    "#     \"err_msg\": \"data empty.\",\n",
    "#     \"sn\": null\n",
    "# }\n",
    "\n",
    "# ——————————————————————————————————————————————————\n",
    "\n",
    "from aip import AipSpeech\n",
    "\n",
    "\"\"\" 你的 APPID AK SK \"\"\"\n",
    "APP_ID = '24910538'\n",
    "API_KEY = 'YO7P7EaATIEzaFhRo6NlpghM'\n",
    "SECRET_KEY = '5ySxlXiddOpXQUMgq9z3I9aaPREmOScG'\n",
    "\n",
    "\n",
    "client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)\n",
    "\n",
    "'''语音识别部分'''\n",
    "file_path=r\"C:\\Users\\hp\\Desktop\\test.pcm\"\n",
    "def Speech():\n",
    "    def get_file_content(filePath):\n",
    "        with open(filePath, \"rb\") as fp:\n",
    "            return fp.read()\n",
    "\n",
    "    keyword = client.asr(get_file_content(file_path), 'pcm', 16000, {'dev_ped': 1537})\n",
    "\n",
    "    print(keyword['err_no'])\n",
    "    print(keyword['err_msg'])\n",
    "    print(keyword['result'][0])\n",
    "     \n",
    "\n",
    "Speech()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【2】百度 短语音识 别接口：Rest API 接口为http 访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【2】百度 短语音识 别接口：Rest API 接口为http 访问， 任意操作系统，任意语言，只要能对baidu域名发起http请求的，均可以使用\n",
    "# 【技术文档】https://ai.baidu.com/ai-doc/SPEECH/ek38lxj1u\n",
    "# 【代码范例】https://github.com/cfy-cfy/speech-demo/tree/master/rest-api-asr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【3】百度 实时语音 识别接口：websocket API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pcm_file=r\"C:\\Users\\hp\\Desktop\\test.pcm\"\n",
    "def send_audio():\n",
    "    chunk_ms = 160  # 160ms的录音\n",
    "    chunk_len = int(chunk_ms*16000 * 2 / 1000)\n",
    "    with open(pcm_file, 'rb') as f:\n",
    "        pcm = f.read()\n",
    "\n",
    "    index = 0\n",
    "    total = len(pcm)\n",
    "    print(\"total: {}\".format(total))\n",
    "    while index < total:\n",
    "        end = index + chunk_len\n",
    "        if end >= total:\n",
    "            # 最后一个音频数据帧\n",
    "            end = total\n",
    "        print(f\"index: {index}, end: {end}\")\n",
    "        index = end    \n",
    "send_audio()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 【3】百度 实时语音 识别接口：websocket API \n",
    "# pip install websocket-client\n",
    "\n",
    "# 【技术文档】https://cloud.baidu.com/doc/SPEECH/s/ek38lxj1u\n",
    "# 【代码范例】https://github.com/cfy-cfy/speech_realtime_api.git/trunk/python-realtime-asr\n",
    "\n",
    "# PID\t模型\t是否有标点及后处理\t备注\n",
    "# 1537\t中文普通话\t无标点\t\n",
    "# 15372\t中文普通话\t加强标点（逗号、句号、问号、感叹号）\t推荐\n",
    "# 1737\t英语\t无标点\t\n",
    "# 17372\t英语\t加强标点（逗号、句号、问号）\n",
    "\n",
    "# 计算方式：\n",
    "# 16000采样率： 1s音频 16000采样点\n",
    "# 16bits： 一个采样点 16bits = 2 bytes\n",
    "# 1s ： = 1000ms\n",
    "# 即 160ms *  16000  * 2bytes / 1000ms = 5120bytes\n",
    "\n",
    "# ——————————————————————————————————\n",
    "import websocket\n",
    "import threading\n",
    "import time\n",
    "import uuid\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# 下面2个是鉴权信息\n",
    "APPID = 24910538\n",
    "APPKEY = 'YO7P7EaATIEzaFhRo6NlpghM'\n",
    "DEV_PID = 15372   # 语言模型 ， 可以修改为其它语言模型测试，如远场普通话19362\n",
    " \n",
    "# 可以改为wss://\n",
    "URI = \"wss://vop.baidu.com/realtime_asr\"\n",
    "pcm_file=r\"C:\\Users\\hp\\Desktop\\test.pcm\"\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\"\"\"\n",
    "1. 连接 ws_app.run_forever()\n",
    "2. 连接成功后发送数据 on_open()\n",
    "2.1 发送开始参数帧 send_start_params()\n",
    "2.2 发送音频数据帧 send_audio()\n",
    "2.3 库接收识别结果 on_message()\n",
    "2.4 发送结束帧 send_finish()\n",
    "3. 关闭连接 on_close()\n",
    "\n",
    "库的报错 on_error()\n",
    "\"\"\"\n",
    "\n",
    "def send_start_params(ws):\n",
    "    \"\"\"\n",
    "    开始参数帧\n",
    "    :param websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    req = {\n",
    "        \"type\": \"START\",\n",
    "        \"data\": {\n",
    "            \"appid\": APPID,    # 网页上的appid\n",
    "            \"appkey\": APPKEY,  # 网页上的appid对应的appkey\n",
    "            \"dev_pid\": DEV_PID,  # 识别模型\n",
    "            \"cuid\": \"1234567\",  # 随便填不影响使用。机器的mac或者其它唯一id，百度计算UV用。\n",
    "            \"sample\": 16000,  # 固定参数\n",
    "            \"format\": \"pcm\"   # 固定参数\n",
    "        }\n",
    "    }\n",
    "    body = json.dumps(req)\n",
    "    ws.send(body, websocket.ABNF.OPCODE_TEXT)\n",
    "#     logger.info(\"send START frame with params:\" + body)\n",
    "\n",
    "def send_audio(ws):\n",
    "    \"\"\"\n",
    "    发送二进制音频数据，注意每个帧之间需要有间隔时间\n",
    "    :param  websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    chunk_ms = 160  # 160ms的录音\n",
    "    chunk_len = int(chunk_ms*16000 * 2 / 1000)\n",
    "    with open(pcm_file, 'rb') as f:\n",
    "        pcm = f.read()\n",
    "\n",
    "    index = 0\n",
    "    total = len(pcm)\n",
    "    logger.info(\"send_audio total={}\".format(total))\n",
    "    while index < total:\n",
    "        end = index + chunk_len\n",
    "        if end >= total:\n",
    "            # 最后一个音频数据帧\n",
    "            end = total\n",
    "        body = pcm[index:end]\n",
    "        logger.debug(\"try to send audio length {}, from bytes [{},{})\".format(len(body), index, end))\n",
    "        ws.send(body, websocket.ABNF.OPCODE_BINARY)\n",
    "        index = end\n",
    "        time.sleep(chunk_ms / 1000.0)  # ws.send 也有点耗时，这里没有计算\n",
    "\n",
    "def send_finish(ws):\n",
    "    \"\"\"\n",
    "    发送结束帧\n",
    "    :param websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    req = { \"type\": \"FINISH\"}\n",
    "    body = json.dumps(req)\n",
    "    ws.send(body, websocket.ABNF.OPCODE_TEXT)\n",
    "    logger.info(\"send FINISH frame\")\n",
    "\n",
    "def send_cancel(ws):\n",
    "    \"\"\"\n",
    "    发送取消帧\n",
    "    :param websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    req = {\"type\": \"CANCEL\"}\n",
    "    body = json.dumps(req)\n",
    "    ws.send(body, websocket.ABNF.OPCODE_TEXT)\n",
    "    logger.info(\"send Cancel frame\")\n",
    "\n",
    "def on_open(ws):\n",
    "    \"\"\"\n",
    "    连接后发送数据帧\n",
    "    :param  websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    def run(*args):\n",
    "        \"\"\"\n",
    "        发送数据帧\n",
    "        :param args:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        send_start_params(ws)\n",
    "        send_audio(ws)\n",
    "        send_finish(ws)\n",
    "        logger.debug(\"thread terminating\")\n",
    "\n",
    "    threading.Thread(target=run).start()\n",
    "\n",
    "def on_message(ws, message):\n",
    "    \"\"\"\n",
    "    接收服务端返回的消息\n",
    "    :param ws:\n",
    "    :param message: json格式，自行解析\n",
    "    :return:\n",
    "    \"\"\"\n",
    "#     logger.info(\"Response: \" + message)\n",
    "    try:\n",
    "        getjs=json.loads(message)\n",
    "        if getjs[\"type\"]==\"FIN_TEXT\" :\n",
    "            logger.info(\"Response: \" + getjs[\"result\"])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def on_error(ws, error):\n",
    "    \"\"\"\n",
    "    库的报错，比如连接超时\n",
    "    :param ws:\n",
    "    :param error: json格式，自行解析\n",
    "    :return:\n",
    "        \"\"\"\n",
    "    logger.error(\"error: \" + str(error))\n",
    "\n",
    "def on_close(ws):\n",
    "    \"\"\"\n",
    "    Websocket关闭\n",
    "    :param websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    logger.info(\"ws close ...\")\n",
    "    # ws.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(format='[%(asctime)-15s] [%(funcName)s()][%(levelname)s] %(message)s')\n",
    "    logger.setLevel(logging.INFO)  # 调整为logging.INFO，日志会少一点,,  logging.DEBUG\n",
    " # ——————————————————————————————————————————   \n",
    "#     formatter = logging.Formatter('[%(asctime)-15s] [%(funcName)s()][%(levelname)s] %(message)s')\n",
    "#     # 设置屏幕打印的格式\n",
    "#     sh = logging.StreamHandler()\n",
    "#     sh.setFormatter(formatter)\n",
    "#     logger.addHandler(sh)\n",
    "    \n",
    "#     #设置log保存\n",
    "#     fh = logging.FileHandler(r\"C:\\Users\\hp\\Desktop\\test_2.log\", encoding='utf8')\n",
    "#     fh.setFormatter(formatter)\n",
    "#     logger.addHandler(fh)\n",
    "# ——————————————————————————————————————————\n",
    "    logger.info(\"begin\")\n",
    "    \n",
    "    # websocket.enableTrace(True)\n",
    "    uri = URI + \"?sn=\" + str(uuid.uuid1())\n",
    "    logger.info(\"uri is \"+ uri)\n",
    "    ws_app = websocket.WebSocketApp(uri,\n",
    "                                    on_open=on_open,  # 连接建立后的回调\n",
    "                                    on_message=on_message,  # 接收消息的回调\n",
    "                                    on_error=on_error,  # 库遇见错误的回调\n",
    "                                    on_close=on_close)  # 关闭后的回调\n",
    "    ws_app.run_forever()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording：倒计时 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-10-06 21:03:59,457] [<module>()][INFO] begin\n",
      "[2021-10-06 21:03:59,480] [<module>()][INFO] uri is wss://vop.baidu.com/realtime_asr?sn=df05c9b0-26a5-11ec-ba71-38eaa7ddb52b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* done recording\n",
      "转为音频文件格式to .pcm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-10-06 21:03:59,857] [send_audio()][INFO] send_audio total=127802\n",
      "[2021-10-06 21:04:03,869] [on_message()][INFO] Response: 恭喜发财，红包拿来。\n",
      "[2021-10-06 21:04:04,006] [send_finish()][INFO] send FINISH frame\n",
      "[2021-10-06 21:04:04,092] [on_close()][INFO] ws close ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;42m 恭喜发财，(*^▽^*) 识别完成！！！ \u001b[0m \n",
      "\n",
      "实时语音识别结果：\u001b[1;30;43m 恭喜发财，红包拿来。  \u001b[Om \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 【3】录音 + 百度 实时语音 识别接口：websocket API \n",
    "\n",
    "# ——————————————————————————————————————————————————————————\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 4\n",
    "WAVE_OUTPUT_FILENAME = r\"C:\\Users\\hp\\Desktop\\output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,channels=CHANNELS,rate=RATE, input=True,frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording：倒计时 5s\")\n",
    "\n",
    "frames = []\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n",
    "# ——————————————————————————————————————————————————————————\n",
    "import os\n",
    "file_path=r\"C:\\Users\\hp\\Desktop\\output.wav\"\n",
    "pcmfile_name=r\"C:\\Users\\hp\\Desktop\\test.pcm\"\n",
    "\n",
    "os.system(f\"ffmpeg -y -i {file_path} -acodec pcm_s16le -f s16le -ac 1 -ar 16000 {pcmfile_name}\")\n",
    "print(\"转为音频文件格式to .pcm\")\n",
    "# ——————————————————————————————————————————————————————————\n",
    "import websocket\n",
    "import threading\n",
    "import time\n",
    "import uuid\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# 下面2个是鉴权信息\n",
    "APPID = 24910538\n",
    "APPKEY = 'YO7P7EaATIEzaFhRo6NlpghM'\n",
    "DEV_PID = 15372   # 语言模型 ， 可以修改为其它语言模型测试，如远场普通话19362\n",
    " \n",
    "# 可以改为wss://\n",
    "URI = \"wss://vop.baidu.com/realtime_asr\"\n",
    "pcm_file=r\"C:\\Users\\hp\\Desktop\\test.pcm\"\n",
    "# pcm_file=r\"C:\\Users\\hp\\Desktop\\VBA+Acrobat\\VBA+Acrobat.pcm\"\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\"\"\"\n",
    "1. 连接 ws_app.run_forever()\n",
    "2. 连接成功后发送数据 on_open()\n",
    "2.1 发送开始参数帧 send_start_params()\n",
    "2.2 发送音频数据帧 send_audio()\n",
    "2.3 库接收识别结果 on_message()\n",
    "2.4 发送结束帧 send_finish()\n",
    "3. 关闭连接 on_close()\n",
    "\n",
    "库的报错 on_error()\n",
    "\"\"\"\n",
    "\n",
    "def send_start_params(ws):\n",
    "    \"\"\"\n",
    "    开始参数帧\n",
    "    :param websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    req = {\n",
    "        \"type\": \"START\",\n",
    "        \"data\": {\n",
    "            \"appid\": APPID,    # 网页上的appid\n",
    "            \"appkey\": APPKEY,  # 网页上的appid对应的appkey\n",
    "            \"dev_pid\": DEV_PID,  # 识别模型\n",
    "            \"cuid\": \"1234567\",  # 随便填不影响使用。机器的mac或者其它唯一id，百度计算UV用。\n",
    "            \"sample\": 16000,  # 固定参数\n",
    "            \"format\": \"pcm\"   # 固定参数\n",
    "        }\n",
    "    }\n",
    "    body = json.dumps(req)\n",
    "    ws.send(body, websocket.ABNF.OPCODE_TEXT)\n",
    "#     logger.info(\"send START frame with params:\" + body)\n",
    "\n",
    "def send_audio(ws):\n",
    "    \"\"\"\n",
    "    发送二进制音频数据，注意每个帧之间需要有间隔时间\n",
    "    :param  websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    chunk_ms = 160  # 160ms的录音\n",
    "    chunk_len = int(chunk_ms*16000 * 2 / 1000)\n",
    "    with open(pcm_file, 'rb') as f:\n",
    "        pcm = f.read()\n",
    "\n",
    "    index = 0\n",
    "    total = len(pcm)\n",
    "    logger.info(\"send_audio total={}\".format(total))\n",
    "    while index < total:\n",
    "        end = index + chunk_len\n",
    "        if end >= total:\n",
    "            # 最后一个音频数据帧\n",
    "            end = total\n",
    "        body = pcm[index:end]\n",
    "        logger.debug(\"try to send audio length {}, from bytes [{},{})\".format(len(body), index, end))\n",
    "        ws.send(body, websocket.ABNF.OPCODE_BINARY)\n",
    "        index = end\n",
    "        time.sleep(chunk_ms / 1000.0)  # ws.send 也有点耗时，这里没有计算\n",
    "\n",
    "def send_finish(ws):\n",
    "    \"\"\"\n",
    "    发送结束帧\n",
    "    :param websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    req = { \"type\": \"FINISH\"}\n",
    "    body = json.dumps(req)\n",
    "    ws.send(body, websocket.ABNF.OPCODE_TEXT)\n",
    "    logger.info(\"send FINISH frame\")\n",
    "\n",
    "def send_cancel(ws):\n",
    "    \"\"\"\n",
    "    发送取消帧\n",
    "    :param websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    req = {\"type\": \"CANCEL\"}\n",
    "    body = json.dumps(req)\n",
    "    ws.send(body, websocket.ABNF.OPCODE_TEXT)\n",
    "    logger.info(\"send Cancel frame\")\n",
    "\n",
    "def on_open(ws):\n",
    "    \"\"\"\n",
    "    连接后发送数据帧\n",
    "    :param  websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    def run(*args):\n",
    "        \"\"\"\n",
    "        发送数据帧\n",
    "        :param args:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        send_start_params(ws)\n",
    "        send_audio(ws)\n",
    "        send_finish(ws)\n",
    "        logger.debug(\"thread terminating\")\n",
    "\n",
    "    threading.Thread(target=run).start()\n",
    "\n",
    "def on_message(ws, message):\n",
    "    global getresult\n",
    "    \"\"\"\n",
    "    接收服务端返回的消息\n",
    "    :param ws:\n",
    "    :param message: json格式，自行解析\n",
    "    :return:\n",
    "    \"\"\"\n",
    "#     logger.info(\"Response: \" + message)\n",
    "    try:\n",
    "        getjs=json.loads(message)\n",
    "        if getjs[\"type\"]==\"FIN_TEXT\" :\n",
    "            getresult=getjs[\"result\"]\n",
    "            logger.info(\"Response: \" + getjs[\"result\"])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def on_error(ws, error):\n",
    "    \"\"\"\n",
    "    库的报错，比如连接超时\n",
    "    :param ws:\n",
    "    :param error: json格式，自行解析\n",
    "    :return:\n",
    "        \"\"\"\n",
    "    logger.error(\"error: \" + str(error))\n",
    "\n",
    "def on_close(ws):\n",
    "    \"\"\"\n",
    "    Websocket关闭\n",
    "    :param websocket.WebSocket ws:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    logger.info(\"ws close ...\")\n",
    "    # ws.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(format='[%(asctime)-15s] [%(funcName)s()][%(levelname)s] %(message)s')\n",
    "    logger.setLevel(logging.INFO)  # 调整为logging.INFO，日志会少一点,,  logging.DEBUG\n",
    " # ——————————————————————————————————————————   \n",
    "#     formatter = logging.Formatter('[%(asctime)-15s] [%(funcName)s()][%(levelname)s] %(message)s')\n",
    "#     # 设置屏幕打印的格式\n",
    "#     sh = logging.StreamHandler()\n",
    "#     sh.setFormatter(formatter)\n",
    "#     logger.addHandler(sh)\n",
    "    \n",
    "#     #设置log保存\n",
    "#     fh = logging.FileHandler(r\"C:\\Users\\hp\\Desktop\\test_2.log\", encoding='utf8')\n",
    "#     fh.setFormatter(formatter)\n",
    "#     logger.addHandler(fh)\n",
    "# ——————————————————————————————————————————\n",
    "    logger.info(\"begin\")\n",
    "    \n",
    "    # websocket.enableTrace(True)\n",
    "    uri = URI + \"?sn=\" + str(uuid.uuid1())\n",
    "    logger.info(\"uri is \"+ uri)\n",
    "    ws_app = websocket.WebSocketApp(uri,\n",
    "                                    on_open=on_open,  # 连接建立后的回调\n",
    "                                    on_message=on_message,  # 接收消息的回调\n",
    "                                    on_error=on_error,  # 库遇见错误的回调\n",
    "                                    on_close=on_close)  # 关闭后的回调\n",
    "    \n",
    "    ws_app.run_forever()\n",
    "    print(\"\\033[1;30;42m 恭喜发财，(*^▽^*) 识别完成！！！ \\033[0m \\n\")\n",
    "    print(f\"实时语音识别结果：\\033[1;30;43m {getresult}  \\033[Om \\n\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【4】PyAudio + wave ： 录音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "# 【4】PyAudio：PyAudio + wave ： 录音\n",
    "# 学习文档 http://people.csail.mit.edu/hubert/pyaudio/\n",
    "# 下载安装源  https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudio\n",
    "#  安装： pip install C:\\Users\\hp\\Desktop\\PyAudio-0.2.11-cp37-cp37m-win_amd64.whl\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 12\n",
    "WAVE_OUTPUT_FILENAME = r\"C:\\Users\\hp\\Desktop\\output1.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【4】PyAudio + wave ： 播放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 【4】PyAudio + wave ： 播放\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    " \n",
    "#define stream chunk \n",
    "chunk = 1024\n",
    " \n",
    "f = wave.open(r\"C:\\Users\\hp\\Desktop\\output1.wav\",\"rb\")\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "#open stream\n",
    "stream = p.open(format = p.get_format_from_width(f.getsampwidth()),\n",
    "                channels = f.getnchannels(),\n",
    "                rate = f.getframerate(),\n",
    "                output = True)\n",
    "#read data\n",
    "data = f.readframes(chunk)\n",
    " \n",
    "#paly stream\n",
    "while data != '':\n",
    "    stream.write(data)\n",
    "    data = f.readframes(chunk)\n",
    " \n",
    "#stop stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    " \n",
    "#close PyAudio\n",
    "p.terminate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
