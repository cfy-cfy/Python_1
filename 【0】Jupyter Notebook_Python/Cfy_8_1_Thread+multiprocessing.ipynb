{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【0】python3 通过两个标准库 _thread 和 threading 提供对线程的支持。\n",
    "\n",
    "（1）_thread 提供了低级别的、原始的线程以及一个简单的锁，它相比于 threading 模块的功能还是比较有限的。\n",
    "\n",
    "（2）threading 模块除了包含 _thread 模块中的所有方法外，还提供的其他方法：\n",
    "\n",
    "        threading.currentThread(): 返回当前的线程变量。\n",
    "        threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。\n",
    "        threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。\n",
    "        除了使用方法外，线程模块同样提供了Thread类来处理线程，Thread类提供了以下方法:\n",
    "\n",
    "        run(): 用以表示线程活动的方法。\n",
    "        start():启动线程活动。\n",
    "        join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。\n",
    "        isAlive(): 返回线程是否活动的。\n",
    "        getName(): 返回线程名。\n",
    "        setName(): 设置线程名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【0】 _thread 库：_thread.start_new_thread ( function, args[, kwargs] )\n",
    "import _thread\n",
    "import time\n",
    "'''____________________________________________'''\n",
    "# def worker(a,b,c):\n",
    "#     print(\"worker %d\" %(a*b*c),\"\\n\")\n",
    "# try:\n",
    "#     _thread.start_new_thread( worker, (2,3,4) )   # 创建两个线程\n",
    "#     _thread.start_new_thread( worker, (1,2,3) )\n",
    "# except:\n",
    "#     print(\"Error: unable to start thread\")\n",
    "# # while 1:\n",
    "# #     pass\n",
    "# _thread.exit() \n",
    "# 线程的结束一般依靠线程函数的自然结束；也可以在线程函数中调用thread.exit()，\n",
    "# 他抛出SystemExit exception，达到退出线程的目的。\n",
    "'''____________________________________________'''\n",
    "n=10\n",
    "def worker(start_num,end_num):\n",
    "    for i in range(start_num,end_num):\n",
    "        print(\"worker %d\" % i*10)\n",
    "try:\n",
    "    _thread.start_new_thread( worker, (1,n*1) ) # 创建4个线程  \n",
    "    _thread.start_new_thread( worker, (n*1,n*2) ) \n",
    "    _thread.start_new_thread( worker, (n*2,n*3) )   \n",
    "    _thread.start_new_thread( worker, (n*3,n*4) )\n",
    "except:\n",
    "    print(\"Error: unable to start thread\")\n",
    "time.sleep(5)\n",
    "_thread.exit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【0】_thread 实例1：多线程爬了最新电影下载链接 https://www.ygdy8.com/\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import _thread\n",
    "import time\n",
    " \n",
    "User_Agent = 'Mozilla/5.0(Macintosh;IntelMacOSX10_7_0)AppleWebKit/535.11(KHTML,likeGecko)Chrome/17.0.963.56Safari/535.11'\n",
    "headers = {'User-Agent': User_Agent,}\n",
    " \n",
    "# 获取每一页的所有电影下载链接\n",
    "def get_new_movie(page):\n",
    "    r = requests.get(url=\"https://www.ygdy8.com/html/gndy/dyzz/list_23_{}.html\".format(page), headers=headers)\n",
    "    r.encoding = 'gb2312'  # 因为该网站的编码是gb2312，所以这里我们需要设置一下编码，否则会报错\n",
    "    html = r.text\n",
    "    name_list = []  # 用来装获取到的电影名称\n",
    "    download_list = []  # 用来装获取到的电影下载链接\n",
    "    bs = BeautifulSoup(html, \"html.parser\")  # 用BeautifulSoup进行html解析\n",
    "    b = bs.findAll(class_=\"co_content8\")\n",
    "    b = b[0].findAll(class_=\"ulink\")  # 此处拿到了每一页中的电影列表\n",
    "    for i in range(0, len(b)):\n",
    "        name = b[i].get_text()  # 获取每个电影的名称\n",
    "#         href = \"https://www.ygdy8.com/\" + b[i].get(\"href\")  # 获取每个电影的详情页面的url\n",
    "        href = \"https://www.ygdy8.com/\" + b[i].attrs[\"href\"]  # 获取每个电影的详情页面的url\n",
    "        name_list.append(name)\n",
    "        download_list.append(href)\n",
    "    return name_list, download_list\n",
    "\n",
    "def get_total_page(url):\n",
    "    r = requests.get(url=url, headers=headers)\n",
    "    r.encoding = 'gb2312'\n",
    "    pattern = re.compile(r'(?<=页/)\\d+')  # re解析  共190页/4741条记录\n",
    "    t = pattern.findall(r.text)\n",
    "    return int(t[0])\n",
    "\n",
    "def wirte_into_csv(name, down_url):\n",
    "    with open(r'C:\\Users\\hp\\Desktop\\最新电影.csv', 'a+', encoding='utf-8') as f:  # a+表示追加\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerow([name, down_url])\n",
    "\n",
    "def run(start_page, end_page):\n",
    "    for p in range(start_page, end_page):\n",
    "        name_list, down_list = get_new_movie(p)\n",
    "        for i in range(0, len(name_list)):\n",
    "            wirte_into_csv(name_list[i], down_list[i])\n",
    "        time.sleep(3)\n",
    "if __name__ == '__main__':\n",
    "#     get_new_movie(1)\n",
    "#     total_page = get_total_page(\"https://www.ygdy8.com/html/gndy/dyzz/list_23_3.html\") # 返回多少条记录\n",
    "#     total_page = int(total_page / 25 + 1) # 返回多少页\n",
    "#     end = int(total_page / 4)\n",
    "    end=1\n",
    "#    创建四个线程，并对其分配任务\n",
    "    try:\n",
    "        _thread.start_new_thread(run, (1, end+1))\n",
    "        _thread.start_new_thread(run, (end + 1, end * 2+1))\n",
    "        _thread.start_new_thread(run, (end * 2 + 1, end * 3+1))\n",
    "        _thread.start_new_thread(run, (end * 3 + 1, end * 4+1))\n",
    "    except:\n",
    "        print(\"Error: 无法启动线程\")\n",
    "#     while (1):\n",
    "#         pass\n",
    "print('ok')\n",
    "_thread.exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【1】threading 库：Thread + start + join \n",
    "'''\n",
    "run(): 用以表示线程活动的方法。\n",
    "start():启动线程活动。\n",
    "join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。\n",
    "isAlive(): 返回线程是否活动的。\n",
    "getName(): 返回线程名。\n",
    "setName(): 设置线程名。\n",
    "'''\n",
    "import threading\n",
    "import time\n",
    "'''____________ 两个线程是同时运行的 _____________________'''\n",
    "# def test():\n",
    "#     for i in range(5):\n",
    "#         print(threading.current_thread().name+' test ',i)\n",
    "#         time.sleep(1)\n",
    "# # thread = threading.Thread(target=test)\n",
    "# thread = threading.Thread(target=test,name='Test_Thread')\n",
    "# thread.start()\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(threading.current_thread().name+' main ',i)\n",
    "#     time.sleep(1)\n",
    "'''____________ 一个先运行，一个后运行 join() 方法，可以阻塞自身所在的线程 _____________________'''\n",
    "def test():\n",
    "    for i in range(5):\n",
    "        print(threading.current_thread().name+' test ',i)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "thread = threading.Thread(target=test,name='Test_Thread')\n",
    "thread.start()\n",
    "# thread.join()  #  默认的情况是，join() 会一直等待对应线程的结束，但可以通过参数赋值，等待规定的时间就好了。\n",
    "thread.join(1)\n",
    "for i in range(5):\n",
    "    print(threading.current_thread().name+' main ', i)\n",
    "    print(thread.name+' is alive ', thread.isAlive())\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【1】threading 库：\n",
    "import threading\n",
    "'''___________________________________________________'''\n",
    "def worker(a,b,c):\n",
    "    print(\"worker %d\" %(a*b*c))\n",
    "    return \"worker %d\"%(a*b*c)\n",
    "thread_1=threading.Thread(target=worker,args=(2,3,4))\n",
    "thread_2=threading.Thread(target=worker,args=(1,2,3))\n",
    "thread_1.start()\n",
    "thread_2.start()\n",
    "thread_1.join()\n",
    "thread_2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【2】multiprocessing 库：Process\n",
    "# idle 或 jupyter 不能执行 print 和 return ,但是在command 运行正常\n",
    "import multiprocessing \n",
    "def print_cube(num): \n",
    "    print(\"Cube: {}\".format(num * num * num)) \n",
    "    return \"Cube: {}\".format(num * num * num)\n",
    "def print_square(num): \n",
    "    print(\"Square: {}\".format(num * num)) \n",
    "    return \"Square: {}\".format(num * num)\n",
    "if __name__ == \"__main__\": \n",
    "    # creating processes \n",
    "    p1 = multiprocessing.Process(target=print_square, args=(10, )) \n",
    "    p2 = multiprocessing.Process(target=print_cube, args=(10, )) \n",
    "    # starting process 1&2\n",
    "    p1.start() \n",
    "    p2.start() \n",
    "    # wait until process 1&2 is finished \n",
    "    p1.join() \n",
    "    p2.join() \n",
    "    # both processes finished \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【2】multiprocessing 库：Pool 线程池 + map \n",
    "# idle 或 jupyter 不能执行 print 和 return ,但是在command 运行正常\n",
    "import multiprocessing\n",
    "def worker(num):\n",
    "    print(\"worker %d\" % num)\n",
    "    return \"worker %d\" % num\n",
    "def main():\n",
    "    pool = multiprocessing.Pool(processes=4) #  创建一个进程池，这里创建了含有4个进程的进程池\n",
    "    results = pool.map(worker, range(10))\n",
    "    pool.close()      # close方法用于关闭进程池，即恢复到没有子进程的情况\n",
    "    pool.join()\n",
    "    for result in results:\n",
    "        print(result)\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "'''\n",
    "对pool1使用map方法，在这个例子中即形成（worker(0),worker(1),worker(2),worker(3),worker(4) 这些任务）\n",
    "这些将执行的任务是按顺序执行的，也就是说进程1执行worker(0)，进程2执行worker(1)，进程3执行worker(2)，\n",
    "进程4执行worker(3)，还多出一个任务则需要等待，等到某个进程提前结束了就再执行这个任务。\n",
    "这样的话相当于一个进程执行一次单独的任务，十分方便某些任务\n",
    "如果函数有返回值即return，还可以使用result = pool1.map(test,list1)获取每个进程的返回值，\n",
    "但是这里是所有返回值在一起，需要自己对其按需处理。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【2】multiprocessing 库：Pool 线程池 +apply 阻塞主进程\n",
    "'''apply阻塞主进程, 并且一个一个按顺序地执行子进程, 等到全部子进程都执行完毕后 ,继续执行apply()后面主进程的代码。'''\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "def doIt(num):\n",
    "    print(\"Process num is : %s\" % num)\n",
    "    time.sleep(1)\n",
    "    print('process  %s end' % num)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('mainProcess start')\n",
    "    start_time = time.time()        # 记录一下开始执行的时间\n",
    "    pool = multiprocessing.Pool(3)  # 创建三个子进程\n",
    "    print('Child start')\n",
    "    for i in range(3):\n",
    "        pool.apply(doIt, [i])\n",
    "    print('mainProcess done time:%s s' % (time.time() - start_time))\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【2】multiprocessing 库：Pool 线程池 + apply_async 非阻塞异步\n",
    "'''apply_async()非阻塞异步的, 他不会等待子进程执行完毕, 主进程会继续执行, 他会根据系统调度来进行进程切换。'''\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "def doIt(num):\n",
    "    print(\"Process num is : %s\" % num)\n",
    "    time.sleep(1)\n",
    "    print('process  %s end' % num)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('mainProcess start')       # 记录一下开始执行的时间\n",
    "    start_time = time.time()\n",
    "    pool = multiprocessing.Pool(3)   # 创建三个子进程\n",
    "    print('Child start')\n",
    "    for i in range(3):\n",
    "        pool.apply_async(doIt, [i])\n",
    "    print('mainProcess done time:%s s' % (time.time() - start_time))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "# CPU在执行第一个子进程的时候, 还没等第一个子进程结束, 系统调度到了按顺序调度到了第二个子进程, 以此类推, \n",
    "# 一直调度运行子进程, 一个接一个地结束子进程的运行, 最后运行主进程, 而且我们可以看到使用apply_async()的执行效力会\n",
    "# 更高, 你看一下他们各自执行结果最后一句的执行消耗时间就知道了, 这也是官方推荐我们使用apply_async()的主要原因吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【3】concurrent.futures 多线程爬虫：\n",
    "import requests\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED\n",
    "\n",
    "def fetch_content(url):\n",
    "    print(url)\n",
    "    headers = {\n",
    "        \"Accept-Encoding\": \"Gzip\",  # 使用gzip压缩传输数据让访问更快\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\"\n",
    "    }\n",
    "    r = requests.get(url, headers=headers)\n",
    "    return r.text\n",
    "\n",
    "url = \"https://movie.douban.com/cinema/later/shenzhen/\"\n",
    "init_page = fetch_content(url)\n",
    "html = etree.HTML(init_page)\n",
    "all_movies = html.xpath(\"//div[@id='showing-soon']/div\")\n",
    "result = []\n",
    "for e in all_movies:\n",
    "#     imgurl, = e.xpath(\".//img/@src\")\n",
    "    name, = e.xpath(\".//div[@class='intro']/h3/a/text()\")\n",
    "    url, = e.xpath(\".//div[@class='intro']/h3/a/@href\")\n",
    "#     date, movie_type, pos = e.xpath(\".//div[@class='intro']/ul/li[@class='dt']/text()\")\n",
    "    like_num, = e.xpath(\n",
    "        \".//div[@class='intro']/ul/li[@class='dt last']/span/text()\")\n",
    "    result.append((name, int(like_num[:like_num.find(\"人\")]), url))\n",
    "main_df = pd.DataFrame(result, columns=[\"影名\", \"想看人数\", \"url\"])\n",
    "\n",
    "max_workers = main_df.shape[0]\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    future_tasks = [executor.submit(fetch_content, url) for url in main_df.url]\n",
    "    wait(future_tasks, return_when=ALL_COMPLETED)\n",
    "    pages = [future.result() for future in future_tasks]\n",
    "\n",
    "result = []\n",
    "for url, html_text in zip(main_df.url, pages):\n",
    "    html = etree.HTML(html_text)\n",
    "    row = {}\n",
    "    for line in re.split(\"[\\n ]*\\n[\\n ]*\", \"\".join(html.xpath(\"//div[@id='info']//text()\")).strip()):\n",
    "        line = line.strip()\n",
    "        arr = line.split(\": \", maxsplit=1)\n",
    "        if len(arr) != 2:\n",
    "            continue\n",
    "        k, v = arr\n",
    "        row[k] = v\n",
    "    row[\"url\"] = url\n",
    "    result.append(row)\n",
    "detail_df = pd.DataFrame(result)\n",
    "df = main_df.merge(detail_df, on=\"url\")\n",
    "df.drop(columns=[\"url\"], inplace=True)\n",
    "df.sort_values(\"想看人数\", ascending=False, inplace=True)\n",
    "df.to_csv(\"shenzhen_movie2.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 【4】nest_asyncio 协程异步爬虫：\n",
    "'''\n",
    "由于在jupyter中运行，为了使协程能够直接在jupyter中直接运行，所以在代码中增加了下面两行代码，\n",
    "在普通编辑器里面可以去掉：\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "这个问题是因为jupyter所依赖的高版本Tornado存在bug，将Tornado退回到低版本也可以解决这个问题。\n",
    "由于request库不支持协程，所以使用了支持协程的aiohttp进行页面抓取。当然实际爬取的耗时还取绝于当时的网络，\n",
    "但整体来说，协程爬取会比多线程爬虫稍微快一些。\n",
    "'''\n",
    "\n",
    "import aiohttp\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import re\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "async def fetch_content(url):\n",
    "    print(url)\n",
    "    header = {\n",
    "        \"Accept-Encoding\": \"Gzip\",  # 使用gzip压缩传输数据让访问更快\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\"\n",
    "    }\n",
    "    async with aiohttp.ClientSession(\n",
    "        headers=header, connector=aiohttp.TCPConnector(ssl=False)\n",
    "    ) as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    url = \"https://movie.douban.com/cinema/later/shenzhen/\"\n",
    "    init_page = await fetch_content(url)\n",
    "    html = etree.HTML(init_page)\n",
    "    all_movies = html.xpath(\"//div[@id='showing-soon']/div\")\n",
    "    result = []\n",
    "    for e in all_movies:\n",
    "        #         imgurl, = e.xpath(\".//img/@src\")\n",
    "        name, = e.xpath(\".//div[@class='intro']/h3/a/text()\")\n",
    "        url, = e.xpath(\".//div[@class='intro']/h3/a/@href\")\n",
    "    #     date, movie_type, pos = e.xpath(\".//div[@class='intro']/ul/li[@class='dt']/text()\")\n",
    "        like_num, = e.xpath(\n",
    "            \".//div[@class='intro']/ul/li[@class='dt last']/span/text()\")\n",
    "        result.append((name, int(like_num[:like_num.find(\"人\")]), url))\n",
    "    main_df = pd.DataFrame(result, columns=[\"影名\", \"想看人数\", \"url\"])\n",
    "\n",
    "    tasks = [fetch_content(url) for url in main_df.url]\n",
    "    pages = await asyncio.gather(*tasks)\n",
    "\n",
    "    result = []\n",
    "    for url, html_text in zip(main_df.url, pages):\n",
    "        html = etree.HTML(html_text)\n",
    "        row = {}\n",
    "        for line in re.split(\"[\\n ]*\\n[\\n ]*\", \"\".join(html.xpath(\"//div[@id='info']//text()\")).strip()):\n",
    "            line = line.strip()\n",
    "            arr = line.split(\": \", maxsplit=1)\n",
    "            if len(arr) != 2:\n",
    "                continue\n",
    "            k, v = arr\n",
    "            row[k] = v\n",
    "        row[\"url\"] = url\n",
    "        result.append(row)\n",
    "    detail_df = pd.DataFrame(result)\n",
    "    df = main_df.merge(detail_df, on=\"url\")\n",
    "    df.drop(columns=[\"url\"], inplace=True)\n",
    "    df.sort_values(\"想看人数\", ascending=False, inplace=True)\n",
    "    return df\n",
    "\n",
    "df = asyncio.run(main())\n",
    "df.to_csv(\"shenzhen_movie3.csv\", index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
