{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# （0）json简介：\n",
    "'''________________________ 1_漂亮的打印出JSON ________________________'''\n",
    "# import json\n",
    "# data={\"status\": \"OK\", \"count\": 2, \"results\": \n",
    "#       [{\"age\": 27, \"name\": \"Oz\", \"lactose_intolerant\": \"true\"}, \n",
    "#       {\"age\": 29, \"name\": \"Joe\", \"lactose_intolerant\": \"false\"}]}\n",
    "# print(json.dumps(data,indent=2))\n",
    "'''________________________ 2 pandas 使嵌套 JSON 秒变 Dataframe ________________________'''\n",
    "# 只深入到嵌套第二级\n",
    "# pd.json_normalize(results, record_path=\"issues\", max_level = 2)\n",
    "\n",
    "'''________________________ 3 Json 字典 格式化与反格式化 ________________________'''\n",
    "\n",
    "import json\n",
    "\n",
    "# 字典\n",
    "data={\"err_msg\":\"OK\",\"err_no\":0,\"log_id\":2100120274,\"result\":\"好\",\n",
    "        \"sn\":\"1f89c138-2525-11ec-a719-38eaa7ddb52b_ws_0\",\"type\":\"MID_TEXT\"}\n",
    "print(data[\"result\"])\n",
    "\n",
    "# 格式化\n",
    "js=json.dumps(data,indent=2)\n",
    "print(js)\n",
    "\n",
    "# 反格式化\n",
    "try:\n",
    "    getjs=json.loads(js)\n",
    "    print(getjs[\"type\"])\n",
    "    print(getjs[\"aa\"])\n",
    "except:\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# （一）requests + json 网易`严选文胸评论：—— https://you.163.com/xhr/search/search.json\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "# 获取产品列表\n",
    "def search_keyword(keyword):\n",
    "    uri = 'https://you.163.com/xhr/search/search.json'\n",
    "    query = {\"keyword\": keyword ,\"page\": 1,\"size\":10}\n",
    "    try:\n",
    "        res = requests.get(uri, params=query).json()\n",
    "        result = res['data']['directly']['searcherResult']['result']\n",
    "        product_id = []\n",
    "        for r in result:\n",
    "            product_id.append(r['id'])\n",
    "        return product_id\n",
    "    except:\n",
    "        raise\n",
    "# # 获取评论\n",
    "def details(product_id):\n",
    "    url = 'https://you.163.com/xhr/comment/listByItemByTag.json'\n",
    "    try:\n",
    "        C_list = []\n",
    "        for i in range(1, 2):\n",
    "            query = {\"itemId\": product_id,\"page\": i,}\n",
    "            res = requests.get(url, params=query).json()\n",
    "            if not res['data']['commentList']:\n",
    "                break\n",
    "            print(\"爬取第 %s 页评论\" % i)\n",
    "            commentList = res['data']['commentList']\n",
    "            C_list.extend(commentList)\n",
    "            time.sleep(1)\n",
    "        return C_list\n",
    "    except:\n",
    "        raise\n",
    "        \n",
    "product_id = search_keyword('文胸')\n",
    "print(product_id)\n",
    "\n",
    "r_list = []\n",
    "for p in product_id:\n",
    "    r_list.extend(details(p))\n",
    "with open('./comments.txt', 'w') as f:\n",
    "    for r in r_list:\n",
    "        try:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + '\\n')\n",
    "        except:\n",
    "            print('出错啦')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# （二）json 结构与美化输出：网易`严选文胸 —— https://you.163.com/xhr/comment/listByItemByTag.json?\n",
    "import json\n",
    "import requests\n",
    "get_comment=[]\n",
    "url_1=\"https://you.163.com/xhr/comment/listByItemByTag.json?__timestamp=1601645976756&itemId=3987228&tag=%E5%85%A8%E9%83%A8&size=20&page=1&orderBy=0&oldItemTag=%E5%85%A8%E9%83%A8&oldItemOrderBy=0&tagChanged=0\"\n",
    "res=requests.get(url_1).json()\n",
    "print(res)\n",
    "commentList = res['data']['commentList']\n",
    "get_comment.extend(commentList)\n",
    "# print(json.dumps(commentList,ensure_ascii=False,indent=1))\n",
    "\n",
    "# url_2=\"https://you.163.com/xhr/comment/listByItemByTag.json?__timestamp=1601645976756&itemId=3987228&tag=%E5%85%A8%E9%83%A8&size=20&page=2&orderBy=0&oldItemTag=%E5%85%A8%E9%83%A8&oldItemOrderBy=0&tagChanged=0\"\n",
    "# res=requests.get(url_2).json()\n",
    "# commentList = res['data']['commentList']\n",
    "# get_comment.extend(commentList)\n",
    "# with open('./commentList.txt','w') as f:\n",
    "#     for cc in commentList:\n",
    "#         f.write(json.dumps(cc,ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# （三）requests + base64 + json + cv2 + numpy + matplotlib 调用AI开放平台：以旷视科技的人脸技术为例\n",
    "'''\n",
    "腾讯 AI 开放平台：https://ai.qq.com/\n",
    "百度 AI 开放平台：https://ai.baidu.com/\n",
    "京东 AI 开放平台：http://neuhub.jd.com/\n",
    "旷视 AI 开放平台：https://www.faceplusplus.com.cn/\n",
    "常见的图像技术、语音技术、文字识别，这些网站都有提供。\n",
    "单看服务数量，百度提供的接口最丰富。\n",
    "旷视，人脸相关的技术，应该是比较好，毕竟早些年支付宝的人脸识别技术，都是旷视提供技术支持的。\n",
    "AI 开放平台提供了丰富的 AI 领域的基础能力，怎么用，用来干什么，就看自己的想象力了。\n",
    "当然，这些免费使用的 API 接口有很多限制，比如不能请求太快等等。\n",
    "想要 API 提供性能更好，QPS 更大的优质服务，那就得充钱了。\n",
    "\n",
    "以旷视科技的人脸技术为例进行测试：\n",
    "原文教程网址：https://mp.weixin.qq.com/s?__biz=MzIxODg1OTk1MA==&mid=2247485136&idx=1&sn=64931d9c8e6e576b1199c8787352b8a6&\n",
    "chksm=97e55611a092df07eb1d9ddfa68a69119fb21f1a7611a402dac9af62ab1d6ffcc8c7ae5dbcf5&scene=178&cur_album_id=1350803219538149376#rd\n",
    "图片地址：\n",
    "https://cuijiahua.com/wp-content/uploads/2020/05/test_1.png\n",
    "（1）首先，创建一个账号。\n",
    "（2）然后，找一个想体验的服务，咱先试试美颜美型：https://www.faceplusplus.com.cn/face-beautify/\n",
    "（3）登录账号，选择控制台，然后创建一个应用，选择「试用」类型。\n",
    "（4）填写一些信息后，就会生成一个 API Key 和 API Secret，这两个是使用 API 接口要用到的参数。\n",
    "    相当于你的个人账号和密码。\n",
    "（5）在控制台，有各种服务的使用说明，比如人脸美颜。\n",
    "    Beautify API v2：https://console.faceplusplus.com.cn/documents/134252584\n",
    "    这个文档，有详细的接口描述，根据这些描述，就可以写代码。\n",
    "'''\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "beautify_url = \"https://api-cn.faceplusplus.com/facepp/v2/beautify\"\n",
    "# 你创建的应用的 API Key 和 API Secret(也叫 Secret Key)\n",
    "AK = 'p4E88XpxMKRdNA_sS5ld3TWoGKBwMpK_'\n",
    "SK = 'vZ4-CHoJSGRxtxiFTabh_ZJuJlW_NtST'\n",
    "\n",
    "# 可选参数，不填写，默认50\n",
    "whitening = 80    # 美白程度 0 - 100\n",
    "smoothing = 90    # 磨皮程度 0 - 100\n",
    "thinface = 20     # 瘦脸程度 0 - 100\n",
    "shrink_face = 50  # 小脸程度 0 - 100\n",
    "enlarge_eye = 50  # 大眼程度 0 - 100\n",
    "remove_eyebrow = 50  # 去眉毛程度 0 - 100\n",
    "filter_type = ''     # 滤镜名称，不填写，默认无滤镜\n",
    "\n",
    "# 二进制方式打开图片，# 必须是英文路径\n",
    "img_name = 'C:\\\\Users\\\\hp\\\\Desktop\\\\Face Beautify API.png'\n",
    "f = open(img_name, 'rb')\n",
    "# 转 base64\n",
    "img_base64 = base64.b64encode(f.read())\n",
    "\n",
    "# 使用 whitening、smoothing、thinface 三个可选参数，其他用默认值\n",
    "data = {'api_key': AK,\n",
    "    'api_secret': SK,\n",
    "    'image_base64': img_base64,  # 传入需要优化的图片：转 base64\n",
    "    'whitening': whitening,\n",
    "    'smoothing': smoothing,\n",
    "    'thinface': thinface,}\n",
    "r = requests.post(url=beautify_url, data=data)\n",
    "html = json.loads(r.text)        # API 接口返回的数据是 base64 的二进制文件\n",
    "\n",
    "# 解析base64图片\n",
    "base64_data = html['result']\n",
    "imgData = base64.b64decode(base64_data)\n",
    "nparr = np.frombuffer(imgData, np.uint8) # uint8是无符号八位整型，表示范围是[0, 255]的整数\n",
    "img_res = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "img_res_BGR = cv2.cvtColor(img_res, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# 原始图片\n",
    "img = cv2.imread(img_name)   # 必须是英文路径\n",
    "img_BGR = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# 显示图片\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(10,10))\n",
    "axs[0].imshow(img_BGR)\n",
    "axs[1].imshow(img_res_BGR)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# （四）base64 + json + cv2 + numpy + matplotlib : 写入并展示图片\n",
    "import base64\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img_name ='C:\\\\Users\\\\hp\\\\Desktop\\\\Face Beautify API.png'\n",
    "'''__________________ 方法1：____________________'''\n",
    "# f = open(img_name, 'rb')\n",
    "# nparr = np.frombuffer(f.read(), np.uint8) # uint8是无符号八位整型，表示范围是[0, 255]的整数\n",
    "# img_res = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "# img_res_BGR = cv2.cvtColor(img_res, cv2.COLOR_RGB2BGR)\n",
    "# fig=plt.imshow(img_res_BGRabs)\n",
    "'''__________________ 方法2：____________________'''\n",
    "# img=plt.imread(img_name) \n",
    "# fig=plt.imshow(img)\n",
    "'''__________________ 方法3：____________________'''\n",
    "# img = cv2.imread(img_name)    # 必须是英文路径\n",
    "# img_BGR = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "# fig=plt.imshow(img_BGR)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# （五）json + execjs + datetime + requests + urllib.parse.urlencode 百度指数：王者荣耀\n",
    "import time\n",
    "import json\n",
    "import execjs  # pip install PyExecJS\n",
    "import datetime\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "def get_data(keywords, startDate, endDate, area):\n",
    "    \"\"\"获取加密的参数数据\"\"\"\n",
    "    # data_url = \"http://index.baidu.com/api/SearchApi/index?area=0&word=[[%7B%22name%22:%22%E7%8E%8B%E8%80%85%E8%8D%A3%E8%80%80%22,%22wordType%22:1%7D]]&startDate=2020-10-01&endDate=2020-10-10\"\n",
    "    params = {'word': json.dumps([[{'name': keyword, 'wordType': 1}] for keyword in keywords]),\n",
    "        'startDate': startDate,'endDate': endDate,'area': area}\n",
    "    data_url = 'http://index.baidu.com/api/SearchApi/index?' + urlencode(params)\n",
    "    print(data_url)\n",
    "    headers = {# 复制登录后的cookie\n",
    "        \"Cookie\": 'BAIDUID=105263D83A6CA7DAF6E92FA1078C647D:FG=1; PSTM=1602161735; BIDUPSID=324C2FF381B2F05DA0A9AF3A86143D86; H_WISE_SIDS=154758_153901_157882_156598_158204_157009_156817_156287_150775_154259_148867_155226_154606_153628_157264_158926_151532_150772_151015_156641_156387_153065_156515_127969_154412_154174_152982_158528_150345_146732_155791_131423_157706_154038_158283_107312_158055_154189_155344_155255_158024_157790_144966_156710_154213_157814_158717_158641_156847_157188_147552_159045_158367_158587_157697_154639_159093_154347_157472_159074_110085_157006; BDUSS=TloWTliQVlQRm9JbFd6bEdNY3dnOVJRY1AwUmQ0TTF6T1Foa3A4dWRaZjN4YjlmRVFBQUFBJCQAAAAAAAAAAAEAAACQf3g3s8K379LHY2Z5AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPc4mF~3OJhfO; __yjsv5_shitong=1.0_7_b134f444b7a7001ed7d7a761294f4d78117d_300_1604321777219_120.84.12.145_6ffe2a37; bdindexid=0s0i98k3dk5nsbd0f6ldihi5s1; Hm_lvt_d101ea4d2a5c67dab98251f0b5de24dc=1603811385,1603975247,1604321651,1604321977; Hm_lpvt_d101ea4d2a5c67dab98251f0b5de24dc=1604322212; RT=\"z=1&dm=baidu.com&si=36foifjisc8&ss=kh0jnn93&sl=a&tt=2ux3&bcn=https%3A%2F%2Ffclog.baidu.com%2Flog%2Fweirwood%3Ftype%3Dperf&ld=db8q',\n",
    "        \"Referer\": \"http://index.baidu.com/v2/main/index.html\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36\"\n",
    "}\n",
    "    # 获取data和uniqid\n",
    "    res = requests.get(url=data_url, headers=headers).json()\n",
    "    print(res)\n",
    "    data = res[\"data\"][\"userIndexes\"][0][\"all\"][\"data\"]\n",
    "    uniqid = res[\"data\"][\"uniqid\"]\n",
    "    # 获取js函数中的参数t = \"ev-fxk9T8V1lwAL6,51348+.9270-%\"\n",
    "    t_url = \"http://index.baidu.com/Interface/ptbk?uniqid={}\".format(uniqid)\n",
    "    rep = requests.get(url=t_url, headers=headers).json()\n",
    "    t = rep[\"data\"]\n",
    "    return {\"data\": data, \"t\": t}\n",
    "\n",
    "def get_search_index(word, startDate, endDate, area):\n",
    "    \"\"\"获取最终数据\"\"\"\n",
    "    word = word\n",
    "    startDate = startDate\n",
    "    endDate = endDate\n",
    "    # 调用get_data获取data和uniqid\n",
    "    res = get_data(word, startDate, endDate, area)\n",
    "    e = res[\"data\"]\n",
    "    t = res[\"t\"]\n",
    "    print(e,t)\n",
    "    # 读取js文件\n",
    "    with open('parsing_data_function.js', encoding='utf-8') as f:\n",
    "        js = f.read()\n",
    "    # 通过compile命令转成一个js对象\n",
    "    docjs = execjs.compile(js)\n",
    "    # 调用function方法,得到指数数值\n",
    "    res = docjs.call('decrypt', t, e)\n",
    "    # print(res)\n",
    "    return res\n",
    "def get_date_list(begin_date, end_date):\n",
    "    \"\"\"获取时间列表\"\"\"\n",
    "    dates = []\n",
    "    dt = datetime.datetime.strptime(begin_date, \"%Y-%m-%d\")\n",
    "    date = begin_date[:]\n",
    "    while date <= end_date:\n",
    "        dates.append(date)\n",
    "        dt += datetime.timedelta(days=1)\n",
    "        date = dt.strftime(\"%Y-%m-%d\")\n",
    "    return dates\n",
    "def get_area():\n",
    "#     areas = {\"901\": \"山东\", \"902\": \"贵州\", \"903\": \"江西\", \"904\": \"重庆\", \"905\": \"内蒙古\", \"906\": \"湖北\", \n",
    "#              \"907\": \"辽宁\", \"908\": \"湖南\", \"909\": \"福建\", \"910\": \"上海\", \"911\": \"北京\", \"912\": \"广西\", \n",
    "#              \"913\": \"广东\", \"914\": \"四川\", \"915\": \"云南\", \"916\": \"江苏\", \"917\": \"浙江\", \"918\": \"青海\",\n",
    "#              \"919\": \"宁夏\", \"920\": \"河北\", \"921\": \"黑龙江\", \"922\": \"吉林\", \"923\": \"天津\", \"924\": \"陕西\",\n",
    "#              \"925\": \"甘肃\", \"926\": \"新疆\", \"927\": \"河南\", \"928\": \"安徽\", \"929\": \"山西\", \"930\": \"海南\", \n",
    "#              \"931\": \"台湾\", \"932\": \"西藏\", \"933\": \"香港\", \"934\": \"澳门\"}\n",
    "    areas = {\"901\": \"山东\"}\n",
    "    for value in areas.keys():\n",
    "        try:\n",
    "            word = ['王者荣耀']\n",
    "            time.sleep(1)\n",
    "            startDate = '2020-10-01'\n",
    "            endDate = '2020-10-10'\n",
    "            area = value\n",
    "            res = get_search_index(word, startDate, endDate, area)\n",
    "            result = res.split(',')\n",
    "            dates = get_date_list(startDate, endDate)\n",
    "            for num, date in zip(result, dates):\n",
    "                print(areas[value], num, date)\n",
    "                with open('area.csv', 'a+', encoding='utf-8') as f:\n",
    "                    f.write(areas[value] + ',' + str(num) + ',' + date + '\\n')\n",
    "        except:\n",
    "            pass\n",
    "def get_word():\n",
    "    words = ['诸葛大力', '张伟', '胡一菲', '吕子乔', '陈美嘉', '赵海棠', '咖喱酱', '曾小贤', '秦羽墨']\n",
    "    for word in words:\n",
    "        try:\n",
    "            time.sleep(2)\n",
    "            startDate = '2020-10-01'\n",
    "            endDate = '2020-10-10'\n",
    "            area = 0\n",
    "            res = get_search_index(word, startDate, endDate, area)\n",
    "            result = res.split(',')\n",
    "            dates = get_date_list(startDate, endDate)\n",
    "            for num, date in zip(result, dates):\n",
    "                print(word, num, date)\n",
    "                with open('word.csv', 'a+', encoding='utf-8') as f:\n",
    "                    f.write(word + ',' + str(num) + ',' + date + '\\n')\n",
    "        except:\n",
    "            pass\n",
    "get_area()\n",
    "# get_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# （六）requests+jsonfake_useragent ：搜狗壁纸 http://pic.sogou.com/pics/channel\n",
    "import requests, json\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "class ShouGO(object):\n",
    "    def __init__(self):\n",
    "        ua = UserAgent(verify_ssl=False)\n",
    "        for i in range(1, 50):\n",
    "            self.headers = {'User-Agent': ua.random,}\n",
    "    def Shou(self, category, length, path):\n",
    "        n = length\n",
    "        cate = category\n",
    "        imgs = requests.get(\n",
    "            'http://pic.sogou.com/pics/channel/getAllRecomPicByTag.jsp?category=' + cate + '&tag=%E5%85%A8%E9%83%A8&start=0&len=' + str(\n",
    "                n))\n",
    "        jd = json.loads(imgs.text)\n",
    "        print(imgs.text)\n",
    "#         jd = jd['all_items']\n",
    "#         imgs_url = []\n",
    "#         for j in jd:\n",
    "#             imgs_url.append(j['pic_url'])\n",
    "#         m = 0\n",
    "#         for img_url in imgs_url:\n",
    "#             # print(img_url)\n",
    "#             print('***** ' + cate + str(m) + '.jpg *****' + '   Downloading...')\n",
    "#             img = requests.get(url=img_url, headers=self.headers).content\n",
    "#             with open(path + cate + str(m) + '.jpg', 'wb') as f:\n",
    "#                 f.write(img)\n",
    "#             m = m + 1\n",
    "#         print('Download complete!')\n",
    "\n",
    "    def main(self):\n",
    "        self.Shou('汽车', 2, './壁纸2/')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Siper = ShouGO()\n",
    "    Siper.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
